/**
 * è¾“å…¥åŒºåŸŸç»„ä»¶
 *
 * ç»Ÿä¸€èŠå¤©å’Œå›¾åƒç”Ÿæˆç•Œé¢ï¼Œæ ¹æ®é€‰æ‹©çš„æ¨¡å‹è‡ªåŠ¨åˆ¤æ–­åŠŸèƒ½
 */

import { useState, useEffect, useCallback } from 'react';
import toast from 'react-hot-toast';
import { createConversation, updateConversation } from '../../services/conversation';
import { type Message } from '../../services/message';
import { uploadAudio } from '../../services/audio';
import { useMessageHandlers } from '../../hooks/useMessageHandlers';
import { useImageUpload } from '../../hooks/useImageUpload';
import { useModelSelection } from '../../hooks/useModelSelection';
import { useAudioRecording } from '../../hooks/useAudioRecording';
import { useSettingsManager } from '../../hooks/useSettingsManager';
import { type UnifiedModel } from '../../constants/models';
import { useTaskStore } from '../../stores/useTaskStore';
import { useChatStore } from '../../stores/useChatStore';
import { createOptimisticUserMessage } from '../../utils/messageFactory';
import { generateClientRequestId } from '../../utils/messageIdMapping';
import ConflictAlert from './ConflictAlert';
import InputControls from './InputControls';
import UploadErrorBar from './UploadErrorBar';

interface InputAreaProps {
  conversationId: string | null;
  /** å½“å‰å¯¹è¯ä¿å­˜çš„æ¨¡å‹ IDï¼ˆç”¨äºæ¢å¤æ¨¡å‹é€‰æ‹©ï¼‰ */
  conversationModelId?: string | null;
  onConversationCreated: (id: string, title: string) => void;
  /** æ¶ˆæ¯å¼€å§‹å‘é€æ—¶è°ƒç”¨ï¼ˆä¹è§‚æ›´æ–°ï¼‰ */
  onMessagePending: (message: Message) => void;
  /** æ¶ˆæ¯å‘é€å®Œæˆæ—¶è°ƒç”¨ï¼Œä¼ é€’ AI å›å¤ */
  onMessageSent: (aiMessage?: Message | null) => void;
  /** æµå¼å†…å®¹æ›´æ–°æ—¶è°ƒç”¨ */
  onStreamContent?: (text: string, conversationId: string) => void;
  /** AIå¼€å§‹ç”Ÿæˆæ—¶è°ƒç”¨ï¼ˆç”¨äºåˆ›å»ºstreamingæ¶ˆæ¯ï¼‰ */
  onStreamStart?: (conversationId: string, model: string) => void;
  /** æ¨¡å‹å˜åŒ–æ—¶è°ƒç”¨ï¼ˆåŒæ­¥ç»™çˆ¶ç»„ä»¶ï¼Œç”¨äºé‡æ–°ç”Ÿæˆï¼‰ */
  onModelChange?: (model: UnifiedModel) => void;
}

export default function InputArea({
  conversationId,
  conversationModelId,
  onConversationCreated,
  onMessagePending,
  onMessageSent,
  onStreamContent,
  onStreamStart,
  onModelChange,
}: InputAreaProps) {
  // åŸºç¡€çŠ¶æ€
  const [prompt, setPrompt] = useState('');
  const [isSubmitting, setIsSubmitting] = useState(false);
  const [uploadError, setUploadError] = useState<string | null>(null);

  // è®¾ç½®ç®¡ç† Hookï¼ˆå›¾åƒ/è§†é¢‘/èŠå¤©å‚æ•°ï¼‰
  const {
    imageSettings,
    setImageSetting,
    videoSettings,
    setVideoSetting,
    chatSettings,
    setChatSetting,
    saveSettings: handleSaveSettings,
    resetSettings: handleResetSettings,
  } = useSettingsManager();

  // å›¾ç‰‡ä¸Šä¼  Hook
  const {
    images,
    uploadedImageUrls,
    previewUrls,
    isUploading,
    uploadError: imageUploadError,
    hasImages,
    handleImageSelect,
    handleImageDrop,
    handleImagePaste,
    handleRemoveImage: removeImageById,
    handleRemoveAllImages,
    clearUploadError,
  } = useImageUpload();

  // éŸ³é¢‘å½•åˆ¶ Hook
  const {
    recordingState,
    audioBlob,
    audioDuration,
    startRecording,
    stopRecording,
    clearRecording,
    error: audioRecordingError,
  } = useAudioRecording();

  // è‡ªåŠ¨ä¿å­˜æ¨¡å‹åˆ°å¯¹è¯çš„å›è°ƒ
  const handleAutoSaveModel = useCallback((modelId: string) => {
    if (conversationId) {
      updateConversation(conversationId, { model_id: modelId }).catch((error) => {
        console.error('ä¿å­˜æ¨¡å‹é€‰æ‹©å¤±è´¥:', error);
      });
    }
  }, [conversationId]);

  // æ¨¡å‹é€‰æ‹© Hookï¼ˆåŒ…å«å¯¹è¯æ¢å¤å’Œæ™ºèƒ½åˆ‡æ¢é€»è¾‘ï¼‰
  const {
    selectedModel,
    modelConflict,
    modelJustSwitched,
    availableModels,
    handleUserSelectModel,
    getSendButtonState,
    getEstimatedCredits,
    getModelSelectorLockState,
  } = useModelSelection({
    hasImage: hasImages,
    conversationId,
    conversationModelId,
    onAutoSaveModel: handleAutoSaveModel,
  });

  // å¯¹è¯åˆ‡æ¢æ—¶é‡ç½®æäº¤çŠ¶æ€
  useEffect(() => {
    setIsSubmitting(false);
  }, [conversationId]);

  // åŒæ­¥ selectedModel ç»™çˆ¶ç»„ä»¶ï¼ˆç”¨äº MessageArea é‡æ–°ç”Ÿæˆï¼‰
  useEffect(() => {
    onModelChange?.(selectedModel);
  }, [selectedModel, onModelChange]);

  // è·å–å½“å‰å¯¹è¯æ ‡é¢˜ï¼ˆç”¨äºä»»åŠ¡è¿½è¸ªï¼‰
  const currentConversationTitle = useChatStore((state) => state.currentConversationTitle);

  // æ¶ˆæ¯å¤„ç† Hook
  const { handleChatMessage, handleImageGeneration, handleVideoGeneration } = useMessageHandlers({
    selectedModel,
    aspectRatio: imageSettings.aspectRatio,
    resolution: imageSettings.resolution,
    outputFormat: imageSettings.outputFormat,
    videoFrames: videoSettings.frames,
    videoAspectRatio: videoSettings.aspectRatio,
    removeWatermark: videoSettings.removeWatermark,
    thinkingEffort: chatSettings.thinkingEffort,
    deepThinkMode: chatSettings.deepThinkMode,
    conversationTitle: currentConversationTitle,
    onMessagePending,
    onMessageSent,
    onStreamContent,
    onStreamStart,
  });

  // åŒæ­¥ä¸Šä¼ é”™è¯¯ï¼ˆç§»åˆ° useEffect é¿å…æ¸²æŸ“æœŸé—´ setStateï¼‰
  useEffect(() => {
    if (imageUploadError && !uploadError) {
      setUploadError(imageUploadError);
    }
  }, [imageUploadError, uploadError]);

  useEffect(() => {
    if (audioRecordingError && !uploadError) {
      setUploadError(audioRecordingError);
    }
  }, [audioRecordingError, uploadError]);

  // åŒ…è£… handleRemoveImage ä»¥æ¸…é™¤é”™è¯¯
  const handleRemoveImage = useCallback((imageId: string) => {
    removeImageById(imageId);
    setUploadError(null);
  }, [removeImageById]);

  // å‘é€éŸ³é¢‘æ¶ˆæ¯
  const handleAudioSubmit = async (audioBlob: Blob) => {
    if (isSubmitting) return;

    setIsSubmitting(true);

    try {
      let currentConversationId = conversationId;

      // å¦‚æœæ˜¯æ–°å¯¹è¯ï¼Œå…ˆåˆ›å»ºå¯¹è¯ï¼ˆåŒæ—¶ä¿å­˜å½“å‰æ¨¡å‹ï¼‰
      if (!currentConversationId) {
        const conversation = await createConversation({
          title: 'è¯­éŸ³å¯¹è¯',
          model_id: selectedModel.id,
        });
        currentConversationId = conversation.id;
        onConversationCreated(currentConversationId, 'è¯­éŸ³å¯¹è¯');
      }

      // ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
      const uploadResult = await uploadAudio(audioBlob);

      // å‘é€æ¶ˆæ¯ï¼ˆå°†éŸ³é¢‘ URL ä½œä¸ºé™„ä»¶ï¼‰
      await handleChatMessage(`[è¯­éŸ³æ¶ˆæ¯]`, currentConversationId, uploadResult.audio_url);
    } catch (error) {
      console.error('å‘é€è¯­éŸ³æ¶ˆæ¯å¤±è´¥:', error);
      setUploadError(error instanceof Error ? error.message : 'è¯­éŸ³ä¸Šä¼ å¤±è´¥');
      onMessageSent(null);
    } finally {
      setIsSubmitting(false);
    }
  };

  // å‘é€æ¶ˆæ¯
  const handleSubmit = async () => {
    // å¦‚æœæœ‰éŸ³é¢‘ï¼Œè°ƒç”¨éŸ³é¢‘æäº¤å¤„ç†
    if (audioBlob) {
      await handleAudioSubmit(audioBlob);
      clearRecording();
      return;
    }

    const sendButtonState = getSendButtonState(isSubmitting, isUploading, !!(prompt.trim() || hasImages));
    if (sendButtonState.disabled) return;

    // æ£€æŸ¥å…¨å±€ä»»åŠ¡é™åˆ¶
    const taskLimitCheck = useTaskStore.getState().canStartTask();
    if (!taskLimitCheck.allowed) {
      toast.error(taskLimitCheck.reason || 'ä»»åŠ¡é˜Ÿåˆ—å·²æ»¡');
      return;
    }

    const messageContent = prompt.trim();
    // å‡†å¤‡å›¾ç‰‡ URLï¼š
    // - previewUrls: æœ¬åœ°é¢„è§ˆ URLï¼ˆObjectURLï¼Œç”¨äºç”¨æˆ·æ¶ˆæ¯ç«‹å³æ˜¾ç¤ºï¼‰
    // - uploadedImageUrls: æœåŠ¡å™¨ URLï¼ˆç”¨äºä¿å­˜åˆ°æ•°æ®åº“å’Œå‘é€ç»™ AIï¼‰
    const combinedPreviewUrl = previewUrls.length > 0 ? previewUrls.join(',') : null;
    const combinedImageUrl = uploadedImageUrls.length > 0 ? uploadedImageUrls.join(',') : null;

    // ç«‹å³æ¸…ç©ºè¾“å…¥ï¼ˆæå‡å“åº”é€Ÿåº¦ï¼‰
    setPrompt('');
    handleRemoveAllImages();  // 30ç§’åæ‰ä¼šæ¸…ç† ObjectURL
    setIsSubmitting(true);

    try {
      const isNewConversation = !conversationId;
      const title = messageContent.slice(0, 20) || 'æ–°å¯¹è¯';

      // ğŸš€ åŒè½¨å¹¶è¡Œä¼˜åŒ–ï¼š
      // ç¬¬ä¸€è½¨ï¼ˆUIå±‚ï¼‰ï¼šç«‹å³å¼€å§‹å¤„ç†æ¶ˆæ¯ï¼ˆä¸é˜»å¡UIï¼‰
      // ç¬¬äºŒè½¨ï¼ˆæ•°æ®å±‚ï¼‰ï¼šåå°åˆ›å»ºå¯¹è¯ï¼ˆå¦‚æœæ˜¯æ–°å¯¹è¯ï¼‰

      // ä½¿ç”¨ä¸´æ—¶å¯¹è¯ ID æˆ–çœŸå®å¯¹è¯ ID
      const currentConversationId = conversationId || `pending-${Date.now()}`;

      // ç«‹å³å¼€å§‹å¤„ç†æ¶ˆæ¯ï¼ˆä¸ç­‰å¾… createConversationï¼‰
      const messagePromise = (async () => {
        if (selectedModel.type === 'chat') {
          // ç”Ÿæˆå”¯ä¸€çš„å®¢æˆ·ç«¯è¯·æ±‚ ID
          const clientRequestId = generateClientRequestId();

          // èŠå¤©æ¶ˆæ¯ï¼šå¦‚æœæœ‰å›¾ç‰‡ï¼Œä½¿ç”¨æœ¬åœ°é¢„è§ˆ URL ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯
          if (combinedPreviewUrl) {
            // ç«‹å³åˆ›å»ºç”¨æˆ·æ¶ˆæ¯ï¼ˆä½¿ç”¨æœ¬åœ°é¢„è§ˆ URLï¼Œç¬é—´æ˜¾ç¤ºï¼‰
            const optimisticMessage = createOptimisticUserMessage(
              messageContent,
              currentConversationId,
              combinedPreviewUrl,  // ä½¿ç”¨ blob:// URL ç«‹å³æ˜¾ç¤º
              undefined,           // createdAt è‡ªåŠ¨ç”Ÿæˆ
              clientRequestId      // ä¼ é€’ client_request_id ç”¨äºåç»­æ›¿æ¢
            );

            // ç«‹å³æ˜¾ç¤ºä¸´æ—¶æ¶ˆæ¯
            onMessagePending(optimisticMessage);

            // è½¬æ¢ä¸º Store çš„ Message ç±»å‹å¹¶æ·»åŠ åˆ°ç¼“å­˜
            const storeMessage = {
              id: optimisticMessage.id,
              role: optimisticMessage.role as 'user' | 'assistant',
              content: optimisticMessage.content,
              imageUrl: optimisticMessage.image_url || undefined,
              videoUrl: optimisticMessage.video_url || undefined,
              createdAt: optimisticMessage.created_at,
              client_request_id: optimisticMessage.client_request_id,
              status: optimisticMessage.status,
            };
            useChatStore.getState().addMessageToCache(currentConversationId, storeMessage);

            // å‘é€åˆ°åç«¯ï¼Œä½¿ç”¨æœåŠ¡å™¨ URLï¼Œè·³è¿‡å†…éƒ¨çš„ä¹è§‚æ›´æ–°ï¼ˆé¿å…é‡å¤ï¼‰
            await handleChatMessage(
              messageContent,
              currentConversationId,
              combinedImageUrl,     // åç«¯ä½¿ç”¨æœåŠ¡å™¨ URLï¼ˆAI éœ€è¦å…¬ç½‘ URLï¼‰
              clientRequestId,      // ä¼ é€’ client_request_id ç”¨äºåç«¯åŒ¹é…
              true                  // skipOptimisticUpdate=trueï¼Œé¿å…é‡å¤åˆ›å»ºä¸´æ—¶æ¶ˆæ¯
            );
          } else {
            // æ²¡æœ‰å›¾ç‰‡æ—¶ï¼Œæ­£å¸¸æµç¨‹ï¼ˆhandleChatMessage å†…éƒ¨åˆ›å»ºä¹è§‚æ¶ˆæ¯ï¼‰
            await handleChatMessage(
              messageContent,
              currentConversationId,
              combinedImageUrl,
              clientRequestId,
              false  // å…è®¸ handleChatMessage åˆ›å»ºä¹è§‚æ¶ˆæ¯
            );
          }
        } else if (selectedModel.type === 'video') {
          await handleVideoGeneration(messageContent, currentConversationId, combinedImageUrl);
        } else {
          await handleImageGeneration(messageContent, currentConversationId, combinedImageUrl);
        }
      })();

      // åå°åˆ›å»ºå¯¹è¯ï¼ˆå¦‚æœæ˜¯æ–°å¯¹è¯ï¼‰
      if (isNewConversation) {
        // ä¸é˜»å¡æ¶ˆæ¯å¤„ç†ï¼Œå¹¶è¡Œåˆ›å»ºå¯¹è¯
        createConversation({
          title,
          model_id: selectedModel.id,
        }).then((conversation) => {
          // é€šçŸ¥çˆ¶ç»„ä»¶å¯¹è¯å·²åˆ›å»º
          onConversationCreated(conversation.id, title);
        }).catch((error) => {
          console.error('åˆ›å»ºå¯¹è¯å¤±è´¥:', error);
          // åˆ›å»ºå¯¹è¯å¤±è´¥ä¸å½±å“æ¶ˆæ¯å‘é€ï¼ˆåç«¯ä¼šè¿‡æ»¤ä¸´æ—¶ IDï¼‰
        });
      }

      // ç­‰å¾…æ¶ˆæ¯å¤„ç†å®Œæˆ
      await messagePromise;
    } catch (error) {
      console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', error);
      setPrompt(messageContent);
      onMessageSent(null);
    } finally {
      setIsSubmitting(false);
    }
  };

  // é”®ç›˜å¿«æ·é”®
  const handleKeyDown = (e: React.KeyboardEvent) => {
    if (e.key === 'Enter' && !e.shiftKey) {
      e.preventDefault();
      handleSubmit();
    }
  };

  const sendButtonState = getSendButtonState(isSubmitting, isUploading, !!(prompt.trim() || hasImages));

  return (
    <div className="bg-white">
      <div className="max-w-3xl mx-auto px-4 pb-4">
        {/* ä¸Šä¼ é”™è¯¯æç¤ºæ¡ */}
        <UploadErrorBar
          error={uploadError}
          onDismiss={() => {
            setUploadError(null);
            clearUploadError();
          }}
        />

        {/* æ¨¡å‹å†²çªè­¦å‘Šæ¡ï¼ˆä¸æ˜¾ç¤º requires_image ç±»å‹ï¼Œæ”¹ç”¨è¾“å…¥æ¡†å†…å¼•å¯¼ï¼‰ */}
        <ConflictAlert
          conflict={modelConflict?.type === 'requires_image' ? null : modelConflict}
          onSwitchModel={handleUserSelectModel}
          onRemoveImage={handleRemoveAllImages}
        />

        {/* ä¸»è¾“å…¥æ§ä»¶ï¼ˆåŒ…å«åº•éƒ¨çš„æ¨¡å‹é€‰æ‹©å™¨ï¼‰ */}
        <InputControls
          prompt={prompt}
          onPromptChange={setPrompt}
          onSubmit={handleSubmit}
          onAudioSubmit={handleAudioSubmit}
          onKeyDown={handleKeyDown}
          isSubmitting={isSubmitting}
          sendButtonDisabled={sendButtonState.disabled}
          sendButtonTooltip={sendButtonState.tooltip}
          selectedModel={selectedModel}
          availableModels={availableModels}
          modelSelectorLocked={getModelSelectorLockState(isUploading).locked}
          modelSelectorLockTooltip={getModelSelectorLockState(isUploading).tooltip}
          onSelectModel={handleUserSelectModel}
          estimatedCredits={getEstimatedCredits(imageSettings.resolution)}
          creditsHighlight={modelJustSwitched}
          aspectRatio={imageSettings.aspectRatio}
          onAspectRatioChange={(v) => setImageSetting('aspectRatio', v)}
          resolution={imageSettings.resolution}
          onResolutionChange={(v) => setImageSetting('resolution', v)}
          outputFormat={imageSettings.outputFormat}
          onOutputFormatChange={(v) => setImageSetting('outputFormat', v)}
          videoFrames={videoSettings.frames}
          onVideoFramesChange={(v) => setVideoSetting('frames', v)}
          videoAspectRatio={videoSettings.aspectRatio}
          onVideoAspectRatioChange={(v) => setVideoSetting('aspectRatio', v)}
          removeWatermark={videoSettings.removeWatermark}
          onRemoveWatermarkChange={(v) => setVideoSetting('removeWatermark', v)}
          thinkingEffort={chatSettings.thinkingEffort}
          onThinkingEffortChange={(v) => setChatSetting('thinkingEffort', v)}
          deepThinkMode={chatSettings.deepThinkMode}
          onDeepThinkModeChange={(v) => setChatSetting('deepThinkMode', v)}
          onSaveSettings={handleSaveSettings}
          onResetSettings={handleResetSettings}
          images={images}
          maxImages={selectedModel.capabilities.maxImages}
          maxFileSize={selectedModel.capabilities.maxFileSize}
          isUploading={isUploading}
          onRemoveImage={handleRemoveImage}
          onImageSelect={handleImageSelect}
          onImageDrop={handleImageDrop}
          onImagePaste={handleImagePaste}
          recordingState={recordingState}
          audioBlob={audioBlob}
          audioDuration={audioDuration}
          onStartRecording={startRecording}
          onStopRecording={stopRecording}
          onClearRecording={clearRecording}
          requiresImageUpload={modelConflict?.type === 'requires_image'}
        />
      </div>
    </div>
  );
}
